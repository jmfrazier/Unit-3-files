{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.4 Challenge\n",
    "\n",
    "Pick a dataset of your choice with a binary outcome and the potential for at least 15 features.\n",
    "\n",
    "Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:\n",
    "\n",
    "Vanilla logistic regression\n",
    "Ridge logistic regression\n",
    "Lasso logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n",
    "                             f1_score)\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent\n",
       "crime</th>\n",
       "      <th>Murder and\n",
       "nonnegligent\n",
       "manslaughter</th>\n",
       "      <th>Rape\n",
       "(revised\n",
       "definition)1</th>\n",
       "      <th>Rape\n",
       "(legacy\n",
       "definition)2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated\n",
       "assault</th>\n",
       "      <th>Property\n",
       "crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-\n",
       "theft</th>\n",
       "      <th>Motor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Arson3</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abernathy</td>\n",
       "      <td>2,821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>119,401</td>\n",
       "      <td>477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>125</td>\n",
       "      <td>314</td>\n",
       "      <td>4,769</td>\n",
       "      <td>1,055</td>\n",
       "      <td>3,460</td>\n",
       "      <td>254</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addison</td>\n",
       "      <td>15,961</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>784</td>\n",
       "      <td>129</td>\n",
       "      <td>593</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alamo</td>\n",
       "      <td>18,876</td>\n",
       "      <td>164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27</td>\n",
       "      <td>126</td>\n",
       "      <td>1,336</td>\n",
       "      <td>203</td>\n",
       "      <td>1,052</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alamo Heights</td>\n",
       "      <td>7,443</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>235</td>\n",
       "      <td>36</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City Population Violent\\ncrime  \\\n",
       "0      Abernathy      2,821              0   \n",
       "1        Abilene    119,401            477   \n",
       "2        Addison     15,961             51   \n",
       "3          Alamo     18,876            164   \n",
       "4  Alamo Heights      7,443              9   \n",
       "\n",
       "   Murder and\\nnonnegligent\\nmanslaughter  Rape\\n(revised\\ndefinition)1  \\\n",
       "0                                     0.0                           0.0   \n",
       "1                                     1.0                           0.0   \n",
       "2                                     1.0                           0.0   \n",
       "3                                     0.0                           0.0   \n",
       "4                                     0.0                           0.0   \n",
       "\n",
       "   Rape\\n(legacy\\ndefinition)2 Robbery Aggravated\\nassault Property\\ncrime  \\\n",
       "0                          0.0       0                   0              12   \n",
       "1                         37.0     125                 314           4,769   \n",
       "2                          4.0      11                  35             784   \n",
       "3                         11.0      27                 126           1,336   \n",
       "4                          2.0       2                   5             235   \n",
       "\n",
       "  Burglary Larceny-\\ntheft Motor\\nvehicle\\ntheft  Arson3  Unnamed: 13  \n",
       "0       12               0                     0     1.0          0.0  \n",
       "1    1,055           3,460                   254    16.0          0.0  \n",
       "2      129             593                    62     1.0          0.0  \n",
       "3      203           1,052                    81     1.0          0.0  \n",
       "4       36             194                     5     0.0          0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading and cleaning from a previous notebook\n",
    "da = pd.read_csv(\n",
    "    r'C:\\Users\\jmfra\\OneDrive\\Documents\\Thinkful Data Science Files\\3.3.4 data\\texas.csv'\n",
    ")\n",
    "da = da.fillna(value=0)\n",
    "da = da[:604]\n",
    "da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adding relevant categories to a new frame\n",
    "dp = pd.DataFrame()\n",
    "dp['Population'] = da[['Population']]\n",
    "dp['Violent_Crime'] = da[['Violent\\ncrime']]\n",
    "dp['Murder'] = da[['Murder and\\nnonnegligent\\nmanslaughter']]\n",
    "dp['Rape1'] = da[['Rape\\n(revised\\ndefinition)1']]\n",
    "dp['Rape2'] = da[['Rape\\n(legacy\\ndefinition)2']]\n",
    "dp['Robbery'] = da[['Robbery']]\n",
    "dp['Burglary'] = da[['Burglary']]\n",
    "dp['Aggravated_Assault'] = da[['Aggravated\\nassault']]\n",
    "dp['Larceny_Theft'] = da[['Larceny-\\ntheft']]\n",
    "dp['Motor_Vehicle_Theft'] = da[['Motor\\nvehicle\\ntheft']]\n",
    "dp['Arson'] = da[['Arson3']]\n",
    "dp['Property_Crime'] = da[['Property\\ncrime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#making all the columns into integers and cleaning\n",
    "dp['Rape'] = dp['Rape1'] + dp['Rape2']\n",
    "dp['Arson'] = dp['Arson'].astype(str)\n",
    "dp = dp.replace({r',': ''}, regex=True)\n",
    "dp['Arson'] = dp.Arson.str.replace('nan','0')\n",
    "dp = dp.apply(pd.to_numeric)\n",
    "dp = dp.drop(['Rape1', 'Rape2', 'Property_Crime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent_Crime</th>\n",
       "      <th>Murder</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Aggravated_Assault</th>\n",
       "      <th>Larceny_Theft</th>\n",
       "      <th>Motor_Vehicle_Theft</th>\n",
       "      <th>Arson</th>\n",
       "      <th>Rape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119401</td>\n",
       "      <td>477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125</td>\n",
       "      <td>1055</td>\n",
       "      <td>314</td>\n",
       "      <td>3460</td>\n",
       "      <td>254</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15961</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>129</td>\n",
       "      <td>35</td>\n",
       "      <td>593</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18876</td>\n",
       "      <td>164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>203</td>\n",
       "      <td>126</td>\n",
       "      <td>1052</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7443</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Population  Violent_Crime  Murder  Robbery  Burglary  Aggravated_Assault  \\\n",
       "0        2821              0     0.0        0        12                   0   \n",
       "1      119401            477     1.0      125      1055                 314   \n",
       "2       15961             51     1.0       11       129                  35   \n",
       "3       18876            164     0.0       27       203                 126   \n",
       "4        7443              9     0.0        2        36                   5   \n",
       "\n",
       "   Larceny_Theft  Motor_Vehicle_Theft  Arson  Rape  \n",
       "0              0                    0    1.0   0.0  \n",
       "1           3460                  254   16.0  37.0  \n",
       "2            593                   62    1.0   4.0  \n",
       "3           1052                   81    1.0  11.0  \n",
       "4            194                    5    0.0   2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making a few of the columns into binary variables based on if they occur or not\n",
    "dp['Violent_Crimec'] = np.where(dp['Violent_Crime'] >= 1, 1, 0)\n",
    "dp['Murderc'] = np.where(dp['Murder'] >= 1, 1, 0)\n",
    "dp['Robberyc'] = np.where(dp['Robbery'] >= 1, 1, 0)\n",
    "dp['Aggravated_Assaultc'] = np.where(dp['Aggravated_Assault'] >= 1, 1, 0)\n",
    "dp['Arsonc'] = np.where(dp['Arson'] >= 1, 1, 0)\n",
    "dp['Rapec'] = np.where(dp['Rape'] >= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ -2.89033293e-05   1.18096235e-02  -1.91567060e-04  -4.43183077e-04\n",
      "    4.14587209e-03   9.40909555e-03   4.70846003e-03  -9.27872293e-05\n",
      "    4.06699022e-04]]\n",
      "[-0.00313571]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc    0    1\n",
      "row_0             \n",
      "0          28    1\n",
      "1         183  392\n",
      "\n",
      " Percentage accuracy\n",
      "0.695364238411\n"
     ]
    }
   ],
   "source": [
    "#robbery has roughly even numbers of 1 and 0 so we will use it as our depenent variable. We will try to predict wether or not\n",
    "#a robbery will occur in a city based on it's other statistics\n",
    "lr = LogisticRegression(C=.1)\n",
    "y = dp['Robberyc']\n",
    "X = dp[['Population', 'Violent_Crime', 'Murder', 'Burglary', 'Aggravated_Assault', 'Larceny_Theft', 'Motor_Vehicle_Theft', 'Arson', 'Rape']]\n",
    "\n",
    "# Fit the model.\n",
    "fit = lr.fit(X, y)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(X)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 1.36403801 -0.55936375 -1.34388299  0.00288484  0.00143466  0.02833138\n",
      "  -1.24179708]]\n",
      "[-1.49594141]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc    0    1\n",
      "row_0             \n",
      "0         207    8\n",
      "1           4  385\n",
      "\n",
      " Percentage accuracy\n",
      "0.980132450331\n"
     ]
    }
   ],
   "source": [
    "#The model in it's base is pretty poor. It looks like a few of the integers imply some variables are not as good estimators as \n",
    "#some of the others, so we will get rid of the ones with a value much closer to 0\n",
    "lr = LogisticRegression(C=.1)\n",
    "y = dp['Robberyc']\n",
    "X = dp[['Violent_Crime', 'Murder', 'Aggravated_Assault', 'Burglary', 'Larceny_Theft', 'Motor_Vehicle_Theft', 'Rape']]\n",
    "\n",
    "# Fit the model.\n",
    "fit = lr.fit(X, y)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(X)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 1.43257012 -0.55044377 -1.39908202 -1.26631682]]\n",
      "[-1.43743333]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc    0    1\n",
      "row_0             \n",
      "0         207    5\n",
      "1           4  388\n",
      "\n",
      " Percentage accuracy\n",
      "0.985099337748\n"
     ]
    }
   ],
   "source": [
    "#This vastly improved the model, but again some of the predictors seem to be much less useful that the others so let's\n",
    "#cut them again\n",
    "lr = LogisticRegression(C=.1)\n",
    "y = dp['Robberyc']\n",
    "X = dp[['Violent_Crime', 'Murder', 'Aggravated_Assault', 'Rape']]\n",
    "\n",
    "# Fit the model.\n",
    "fit = lr.fit(X, y)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(X)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now that we have a working model, lets test for confidence\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 1.24884352 -0.38382156 -1.21640515 -1.09955832]]\n",
      "[-1.35980321]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc    0    1\n",
      "row_0             \n",
      "0         167   11\n",
      "1           4  271\n",
      "\n",
      " Percentage accuracy\n",
      "0.966887417219\n"
     ]
    }
   ],
   "source": [
    "# Fit the model.\n",
    "fit = lr.fit(xtrain, ytrain)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(xtrain)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, ytrain))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 1.24884352 -0.38382156 -1.21640515 -1.09955832]]\n",
      "[-1.35980321]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc   0    1\n",
      "row_0            \n",
      "0         40    7\n",
      "1          0  104\n",
      "\n",
      " Percentage accuracy\n",
      "0.953642384106\n"
     ]
    }
   ],
   "source": [
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(xtest)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, ytest))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these values are very similar so lets test lasso regression and see its relation to the ridge above\n",
    "lr = LogisticRegression(penalty='l1', C=.1)\n",
    "y = dp['Robberyc']\n",
    "X = dp[['Population', 'Violent_Crime', 'Murder', 'Burglary', 'Aggravated_Assault', 'Larceny_Theft', 'Motor_Vehicle_Theft', 'Arson', 'Rape']]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[  5.23502863e-05   7.48398847e-03   0.00000000e+00   2.48961894e-03\n",
      "    2.72600150e-02   4.45690609e-04   4.99721643e-03   0.00000000e+00\n",
      "   -1.49061552e-03]]\n",
      "[-0.34615965]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc   0    1\n",
      "row_0            \n",
      "0         98   26\n",
      "1         56  273\n",
      "\n",
      " Percentage accuracy\n",
      "0.818984547461\n"
     ]
    }
   ],
   "source": [
    "# Fit the model.\n",
    "fit = lr.fit(xtrain, ytrain)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(xtrain)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, ytrain))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looks like changing the penalty type changes the important variables\n",
    "X = dp[['Aggravated_Assault', 'Motor_Vehicle_Theft', 'Arson', 'Rape']]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 0.00926865  0.08741887  0.02859147  0.10781651]]\n",
      "[-0.35420339]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc    0    1\n",
      "row_0             \n",
      "0         107   43\n",
      "1          49  254\n",
      "\n",
      " Percentage accuracy\n",
      "0.796909492274\n"
     ]
    }
   ],
   "source": [
    "# Fit the model.\n",
    "fit = lr.fit(xtrain, ytrain)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(xtrain)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, ytrain))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 0.00926865  0.08741887  0.02859147  0.10781651]]\n",
      "[-0.35420339]\n",
      "\n",
      " Accuracy by admission status\n",
      "Robberyc   0   1\n",
      "row_0           \n",
      "0         42  13\n",
      "1         13  83\n",
      "\n",
      " Percentage accuracy\n",
      "0.827814569536\n"
     ]
    }
   ],
   "source": [
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(xtest)\n",
    "\n",
    "print('\\n Accuracy by admission status')\n",
    "print(pd.crosstab(pred_y_sklearn, ytest))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439018\n",
      "         Iterations 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1b59ce1dac8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(y, X)\n",
    "model.fit(maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441491\n",
      "         Iterations 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1b59ce1de10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(ytrain, xtrain)\n",
    "model.fit(maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.423553\n",
      "         Iterations 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1b59ce1d0f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(ytest, xtest)\n",
    "model.fit(maxiter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of C was chosen at .1 because ridge regression had a perfect score using the default, and since our prupose in this notebook was to compare models, we wanted to use a value that would gaurentee comparable results.\n",
    "\n",
    "In this situation, Vanilla logistic regression is by far the worst regression type with under a .5 score and ridge regression is by far the best. It is important to note that feature selection in ridge regression improved the model's strength by almost 30% while feature selection in lasso didn't improve the model at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
